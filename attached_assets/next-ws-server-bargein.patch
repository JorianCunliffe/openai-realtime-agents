--- a/src/server/next-ws-server.ts
+++ b/src/server/next-ws-server.ts
@@ -7,6 +7,8 @@
 // ---- Realtime config ----
 const REALTIME_MODEL = process.env.REALTIME_MODEL || "gpt-realtime";
 const VOICE = process.env.REALTIME_VOICE || "alloy";
+const SPEAK_FIRST_DEFAULT = String(process.env.REALTIME_SPEAK_FIRST || "false").toLowerCase() === "true";
+const SHOW_TIMING_MATH = String(process.env.SHOW_TIMING_MATH || "false").toLowerCase() === "true";
 if (!process.env.OPENAI_API_KEY) {
   console.error("OPENAI_API_KEY missing");
 }
@@ -15,7 +17,7 @@
 const app = next({ dev });
 const handle = app.getRequestHandler();
 
-type UserCtx = { userId: string; callSid?: string; streamSid?: string };
+type UserCtx = { userId: string; callSid?: string; streamSid?: string; speakFirst?: boolean };
 
 // --- OpenAI Realtime session factory ---
 async function createRealtimeSession(ctx: UserCtx): Promise<{
@@ -74,47 +76,51 @@
   rt.on("open", () => {
     open = true;
     console.log("[Realtime] open");
 
     // ✅ Legacy/flat session payload expected by your server
     const sessionUpdate = {
       type: "session.update",
       session: {
         turn_detection: { type: "server_vad" },    // top-level
         input_audio_format: "g711_ulaw",           // Twilio PCMU in
         output_audio_format: "g711_ulaw",          // PCMU back to Twilio
         voice: VOICE,
         instructions: "You are a helpful, concise voice assistant for phone calls.",
         modalities: ["text", "audio"],             // <- legacy servers accept this
         // optional knobs if you want them:
         // temperature: 0.8,
       },
     };
     console.log("[Realtime] session.update sent");
     rt.send(JSON.stringify(sessionUpdate));
 
-    // Have the model speak first (and force dual modalities as required)
-    const greeting = {
-      type: "conversation.item.create",
-      item: {
-        type: "message",
-        role: "user",
-        content: [
-          { type: "input_text", text: "Greet the caller briefly (under 5 seconds). Introduce yourself and ask how you can help." },
-        ],
-      },
-    };
-    rt.send(JSON.stringify(greeting));
-    console.log("[Realtime] greeting item sent");
-
-    rt.send(JSON.stringify({
-      type: "response.create",
-      response: { modalities: ["audio", "text"] }  // <- your server requires audio+text (not audio-only)
-    }));
-    console.log("[Realtime] response.create (greeting) sent");
+    // Have the model speak first (optional)
+    if (ctx.speakFirst) {
+      const greeting = {
+        type: "conversation.item.create",
+        item: {
+          type: "message",
+          role: "user",
+          content: [
+            { type: "input_text", text: "Greet the caller briefly (under 5 seconds). Introduce yourself and ask how you can help." },
+          ],
+        },
+      };
+      rt.send(JSON.stringify(greeting));
+      console.log("[Realtime] greeting item sent");
+
+      rt.send(JSON.stringify({
+        type: "response.create",
+        response: { modalities: ["audio", "text"] }  // <- your server requires audio+text (not audio-only)
+      }));
+      console.log("[Realtime] response.create (greeting) sent");
+    }
   });
 
   rt.on("error", (e) => console.log("[Realtime] error", e));
   rt.on("close", (code, reason) => {
     open = false;
     console.log("[Realtime] close", code, reason?.toString());
   });
 
   return {
     socket: rt,
     sendAudio: (b64: string) => {
       if (!open) return;
@@ -168,12 +174,20 @@
   wss.on("connection", (ws: WebSocket, _request: http.IncomingMessage, userCtx: UserCtx) => {
     console.log(`[WS] Connected: userId=${userCtx.userId}`);
     let session: Awaited<ReturnType<typeof createRealtimeSession>> | null = null;
     let streamSid: string | null = null;
+    let latestMediaTimestamp: number = 0;
+    let lastAssistantItem: string | null = null;
+    let markQueue: string[] = [];
+    let responseStartTimestampTwilio: number | null = null;
 
     // Twilio media diagnostics
     let mediaCount = 0;
     let firstMediaAt: number | null = null;
     let bytesAccum = 0;
     let lastRateAt = Date.now();
 
+    // Send a Twilio mark to delimit playback chunks
+    const sendMark = () => {
+      if (!streamSid) return;
+      const mark = { event: "mark", streamSid, mark: { name: "responsePart" } };
+      ws.send(JSON.stringify(mark));
+      markQueue.push("responsePart");
+    };
+
+    // Handle barge-in when the caller starts speaking
+    const handleSpeechStartedEvent = () => {
+      if (markQueue.length > 0 && responseStartTimestampTwilio !== null) {
+        const elapsed = Math.max(0, latestMediaTimestamp - responseStartTimestampTwilio);
+        if (SHOW_TIMING_MATH) {
+          console.log(`[barge-in] elapsed=${latestMediaTimestamp} - ${responseStartTimestampTwilio} = ${elapsed}ms`);
+        }
+        if (lastAssistantItem) {
+          const truncateEvent = {
+            type: "conversation.item.truncate",
+            item_id: lastAssistantItem,
+            content_index: 0,
+            audio_end_ms: elapsed,
+          };
+          if (SHOW_TIMING_MATH) console.log("[truncate]", JSON.stringify(truncateEvent));
+          session?.socket?.send(JSON.stringify(truncateEvent));
+        }
+        if (streamSid) {
+          ws.send(JSON.stringify({ event: "clear", streamSid }));
+        }
+        // reset
+        markQueue = [];
+        lastAssistantItem = null;
+        responseStartTimestampTwilio = null;
+      }
+    };
+
     ws.on("message", async (data) => {
       let msg: { event: string; [k: string]: any };
       try {
         msg = JSON.parse(data.toString());
       } catch {
@@ -198,24 +212,37 @@
           session = await createRealtimeSession(userCtx);
 
           // Model → Twilio: forward audio deltas, with counters
           // Model → Twilio: forward audio deltas, with counters
           let deltaCount = 0;
           session.socket.on("message", (raw) => {
             try {
               const evt = JSON.parse(raw.toString());
 
               // Always log event type
               console.log("[Realtime] any evt:", evt.type);
 
               // Show payload head for any response.* event that's not a big audio delta
-              if (evt.type?.startsWith?.("response.") && evt.type !== "response.audio.delta") {
+              if (evt.type?.startsWith?.("response.") && evt.type !== "response.audio.delta" && evt.type !== "response.output_audio.delta") {
                 console.log("[Realtime] response payload head:", JSON.stringify(evt).slice(0, 400));
               }
 
-              // ✅ Forward actual audio chunks you receive
-              if (streamSid && evt.type === "response.audio.delta" && typeof evt.delta === "string") {
+              // ✅ Forward actual audio chunks you receive (support both event keys)
+              const isDelta = (evt.type === "response.audio.delta" || evt.type === "response.output_audio.delta") && typeof evt.delta === "string";
+              if (streamSid && isDelta) {
                 deltaCount++;
                 if (deltaCount % 50 === 1) console.log("[Realtime] audio delta#", deltaCount, "b64len", evt.delta.length);
                 ws.send(JSON.stringify({ event: "media", streamSid, media: { payload: evt.delta } }));
+                if (!responseStartTimestampTwilio) {
+                  responseStartTimestampTwilio = latestMediaTimestamp;
+                  if (SHOW_TIMING_MATH) console.log(`[audio-start] responseStartTimestampTwilio=${responseStartTimestampTwilio}ms`);
+                }
+                if (evt.item_id) lastAssistantItem = evt.item_id as string;
+                sendMark();
                 if (deltaCount % 50 === 1) console.log("[Twilio<-Model] forwarded delta#", deltaCount);
 
-              } else if (evt.type !== "response.audio.delta") {
+              } else if (evt.type !== "response.audio.delta" && evt.type !== "response.output_audio.delta") {
                 //log text output
                 if (evt.type === "response.output_text.delta") {
                   console.log("[Realtime] text-delta:", JSON.stringify(evt, null, 2));
                 }
                 // log a few interesting non-delta events
                 if ([
                   "session.updated",
                   "response.created",
                   "response.completed",
                   "response.content.done",
                   "error",
                   "rate_limits.updated"
                 ].includes(evt.type)) {
                   console.log("[Realtime] evt", evt.type);
                 }
+
+                // Barge-in trigger from server VAD
+                if (evt.type === "input_audio_buffer.speech_started") {
+                  handleSpeechStartedEvent();
+                }
               }
 
             } catch (e) {
               console.error("[Realtime] parse message err", e);
             }
           });
           break;
         }
@@ -250,6 +277,7 @@
           }
 
           // Twilio → Model
+          latestMediaTimestamp = typeof m.media?.timestamp === "number" ? m.media.timestamp : latestMediaTimestamp;
           session?.sendAudio(m.media.payload);
           break;
         }
 
-        case "mark":
-          // optional timing
+        case "mark":
+          // Twilio acknowledged a mark we sent; pop one
+          if (markQueue.length > 0) markQueue.shift();
           break;
 
         case "stop": {
           const secs = firstMediaAt ? ((Date.now() - firstMediaAt) / 1000).toFixed(1) : "0";
           console.log("[Twilio][stop]", { streamSid: msg.streamSid, mediaCount, firstMediaAfterSec: secs });
@@ -310,9 +338,13 @@
     if (url.pathname !== "/twilio-media") {
       socket.write("HTTP/1.1 404 Not Found\r\n\r\n");
       socket.destroy();
       return;
     }
-    const userId = String(url.query.userId ?? "guest");
-    const userCtx: UserCtx = { userId };
+    const userId = String(url.query.userId ?? "guest");
+    const sf = String(url.query.speakFirst ?? "").toLowerCase();
+    const speakFirst = sf === "1" || sf === "true" ? true : sf === "0" || sf === "false" ? false : SPEAK_FIRST_DEFAULT;
+    const userCtx: UserCtx = { userId, speakFirst };
     wss.handleUpgrade(req, socket, head, (ws) => {
       wss.emit("connection", ws, req, userCtx);
     });
   });
 
